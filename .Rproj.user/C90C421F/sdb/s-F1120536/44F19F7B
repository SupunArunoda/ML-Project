{
    "collab_server" : "",
    "contents" : "traindata <- read.csv(\"traindata.csv\", header = T) #Read Train Data\nlabeldata <- read.csv(\"label.csv\", header = T) #Read Train Data Labels\ntestdata <- read.csv(\"testdata.csv\", header = T) #Read Test Data\ntraindata$status_group <- labeldata$status_group #Add Train Data Labels to Actual Data\n\n#Creating a New attribute called 'years in operation(yip)'\ntmp <- format(as.Date(traindata$date_recorded, '%Y-%m-%d'),'%Y') \ntmp <- as.numeric(tmp)\ntraindata$yip <- tmp - traindata$construction_year\ntraindata$yip[traindata$yip > 2000] <- 0\n\n#Removing Attributes-based on redundancy and logical reasoning\ntraindata$num_private <- NULL\ntraindata$wpt_name <- NULL\ntraindata$subvillage <- NULL\ntraindata$region_code <- NULL\ntraindata$region <- NULL\ntraindata$ward <- NULL\ntraindata$recorded_by <- NULL\ntraindata$scheme_name <- NULL\ntraindata$permit <- NULL\ntraindata$extraction_type <- NULL\ntraindata$extraction_type_class <- NULL\ntraindata$management_group <- NULL\ntraindata$quality_group <- NULL\ntraindata$quantity_group <- NULL\ntraindata$waterpoint_type_group <- NULL\ntraindata$source_type <- NULL\n# traindata$latitude <- NULL\n# traindata$longitude <- NULL\n#traindata$funder <- NULL\n#traindata$installer <- NULL\ntraindata$date_recorded <- NULL\n\n#factoring attributes\ntraindata$basin <- as.factor(traindata$basin)\n#traindata$region <- as.factor(traindata$region)\ntraindata$public_meeting <- as.factor(traindata$public_meeting)\ntraindata$scheme_management <- as.factor(traindata$scheme_management)\ntraindata$extraction_type_group <- as.factor(traindata$extraction_type_group)\ntraindata$management <- as.factor(traindata$management)\ntraindata$payment <- as.factor(traindata$payment)\ntraindata$payment_type <- as.factor(traindata$payment_type)\ntraindata$water_quality <- as.factor(traindata$water_quality)\ntraindata$waterpoint_type <- as.factor(traindata$waterpoint_type)\ntraindata$quantity <- as.factor(traindata$quantity)\ntraindata$source <- as.factor(traindata$source)\ntraindata$source_class <- as.factor(traindata$source_class)\ntraindata$status_group <- as.factor(traindata$status_group)\n\n#Removing NAs from attribute\ntraindata$public_meeting <- factor(traindata$public_meeting, levels = c(\"FALSE\",\"TRUE\",\"\"))\ntraindata$public_meeting[is.na(traindata$public_meeting)] <- \"\"\n\n#Creating New attribute called 'YIP' for testdata\ntmp1 <- format(as.Date(testdata$date_recorded, '%Y-%m-%d'),'%Y')\ntmp1 <- as.numeric(tmp1)\n\ntestdata$yip <- tmp1 - testdata$construction_year\ntestdata$yip[testdata$yip > 2000] <- 0\n\n#Removing redundant and unimportant attributes\ntestdata$num_private <- NULL\ntestdata$wpt_name <- NULL\ntestdata$subvillage <- NULL\ntestdata$region_code <- NULL\ntestdata$region <- NULL\ntestdata$ward <- NULL\ntestdata$recorded_by <- NULL\ntestdata$scheme_name <- NULL\ntestdata$permit <- NULL\ntestdata$extraction_type <- NULL\ntestdata$extraction_type_class <- NULL\ntestdata$management_group <- NULL\ntestdata$quality_group <- NULL\ntestdata$quantity_group <- NULL\ntestdata$waterpoint_type_group <- NULL\ntestdata$source_type <- NULL\n# testdata$latitude <- NULL\n# testdata$longitude <- NULL\n#testdata$funder <- NULL\n#testdata$installer <- NULL\ntestdata$date_recorded <- NULL\n\ntestdata$public_meeting <- casefold(testdata$public_meeting, upper = TRUE)\ntestdata$public_meeting <- as.factor(testdata$public_meeting)\nlevels(testdata$scheme_management) <- levels(traindata$scheme_management)\n\n#Diving the training data into Training and Validation Set\nlabeldata <- traindata$status_group\nlabeldata <- as.numeric(labeldata)\nTL <- labeldata[1:53460] \nVL <- labeldata[53461:59400]\ntraindata <- traindata[-grep('status_group',colnames(traindata))]\nvaliddata <- traindata[53461:59400,] #validation set-10% of data\ntraindata <- traindata[1:53460,] #training set-90% of data\nalldata <- rbind(traindata, validdata,testdata) #Combining all the data\nTL <- TL - 1\nVL <- VL - 1\n\n\n# library(Matrix)\n# install.packages(\"chron\", dependencies = T)\n# require(xgboost)\n\n#Converting all the data to numeric and factoring levels\ncols <- names(alldata)\nfor(i in cols){\n  if(class(alldata[[i]])==\"character\"){\n    levels <- unique(c(alldata[[i]]))\n    alldata[[i]] <- as.numeric(factor(D[[i]], levels = levels))\n  }\n  if(class(alldata[[i]])==\"factor\"){\n    alldata[[i]] <- as.numeric(alldata[[i]])\n  }\n}\n\n#Subsetting the data\nalldata.xgb <- subset(alldata, select = c(-district_code,-id))\nalldata.xgb <- as.matrix(as.data.frame(lapply(alldata.xgb,as.numeric)))\n\n#Breaking the dataset again\ntrain.xgb <- alldata.xgb[1:53460,]\nvalid.xgb <- alldata.xgb[53461:59400,]\ntest.xgb <- alldata.xgb[59401:74250,]\n\n#Converting the data into DMatrix format\nnewtrain <- xgb.DMatrix(train.xgb, label = TL)\nnewvalid <- xgb.DMatrix(valid.xgb, label = VL)\nnewtest <- xgb.DMatrix(test.xgb)\nprint(\"hello\")\naccuracies <- 0\nfor(i in 9:9){\n  set.seed(i)\n  print(i)\n  #set.seed(2*i+1)\n  #list of parameters for Gradient Boosting\n  param.xgb <- list(objective = \"multi:softmax\",eval_metric = \"merror\",num_class = 3,\n                    booster = \"gbtree\",eta = 0.2,subsample = 0.7,colsample_bytree = 0.4,\n                    max_depth = 14)\n  print(\"hello\")\n  results <- xgb.cv(params = param.xgb, newtrain, nrounds = 200, nfold = 10,\n              early.stop.round = 20,maximize = FALSE, print.every.n = 10)\n  #Creating the Gradient Boosting Model\n  model.xgb <- xgb.train(data = newtrain, param.xgb, nrounds = 38, watchlist = list(valid = newvalid, train = newtrain),\n                         nfold = 10, early.stop.round = 20, print.every.n = 10,\n                         maximize = FALSE,save_name = \"model.xgb\")\n  #early.stop.round = 20,\n  \n  #Testing the model against Validation Set\n  pred.valid <- predict(model.xgb, newvalid)\n  output.valid <- data.frame(id = validdata$id, status_group = pred.valid)\n  output.valid$status_group[output.valid$status_group == 0] = \"functional\";\n  output.valid$status_group[output.valid$status_group == 1] = \"functional needs repair\";\n  output.valid$status_group[output.valid$status_group == 2] = \"non functional\";\n  \n  VL[VL == 0] = \"functional\"\n  VL[VL == 1] = \"functional needs repair\"\n  VL[VL == 2] = \"non functional\"\n  print(mean(output.valid$status_group == VL))\n  #accuracies[i] <- mean(output.valid$status_group == VL)\n}\n#Testing the model against test data\npred.test <- predict(model.xgb, newtest)\noutput.test <- data.frame(id = testdata$id, status_group = pred.test)\noutput.test$status_group[output.test$status_group == 0] = \"functional\";\noutput.test$status_group[output.test$status_group == 1] = \"functional needs repair\";\noutput.test$status_group[output.test$status_group == 2] = \"non functional\";\nprint(\"hello\")\nwrite.csv(output.test, file = \"submissionSeed9_1.csv\", row.names = F)\n\n",
    "created" : 1495217543018.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3012333316",
    "id" : "44F19F7B",
    "lastKnownWriteTime" : 1495178556,
    "last_content_update" : 1495178556,
    "path" : "E:/Acadamic/Semester 7/Machine Learning/Project/PumpItUp_withreport/XGB.r",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}